{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13a6a342",
   "metadata": {},
   "source": [
    "# BabyCoach Data Exploration\n",
    "\n",
    "This notebook explores the structure and content of the Evernote corpus to understand:\n",
    "\n",
    "1. **Data Structure**: JSON format, fields, and schema\n",
    "2. **Content Analysis**: Note lengths, tag distribution, date ranges\n",
    "3. **Chunking Strategy**: Evaluate different approaches for RAG\n",
    "4. **Embedding Preparation**: Identify optimal text processing pipeline\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f75bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "print(\"‚úÖ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617de09f",
   "metadata": {},
   "source": [
    "## Load and Inspect Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7473ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the corpus data\n",
    "corpus_path = Path('../data/corpus.json')\n",
    "\n",
    "if not corpus_path.exists():\n",
    "    print(f\"‚ùå Corpus file not found at {corpus_path}\")\n",
    "    print(\"Make sure the symbolic link is set up correctly:\")\n",
    "    print(\"ln -s ~/Desktop/evernote_rag_export.json ../data/corpus.json\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loading corpus from {corpus_path}\")\n",
    "    \n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        corpus_data = json.load(f)\n",
    "    \n",
    "    print(f\"üìä Loaded {len(corpus_data)} notes\")\n",
    "    print(f\"üìÅ File size: {corpus_path.stat().st_size / (1024*1024):.1f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a1391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the structure of a few notes\n",
    "print(\"=== Sample Note Structure ===\")\n",
    "if corpus_data:\n",
    "    sample_note = corpus_data[0]\n",
    "    print(f\"Sample note keys: {list(sample_note.keys())}\")\n",
    "    print(\"\\n=== Sample Note ===\\n\")\n",
    "    for key, value in sample_note.items():\n",
    "        if key == 'text':\n",
    "            print(f\"{key}: {str(value)[:200]}...\" if len(str(value)) > 200 else f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3e7d5c",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9caa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "if corpus_data:\n",
    "    # Extract metadata into separate columns\n",
    "    df_data = []\n",
    "    for note in corpus_data:\n",
    "        row = {\n",
    "            'id': note['id'],\n",
    "            'text': note['text'],\n",
    "            'text_length': len(note['text']),\n",
    "            'title': note['metadata'].get('title', ''),\n",
    "            'tags': note['metadata'].get('tags', []),\n",
    "            'tag_count': len(note['metadata'].get('tags', [])),\n",
    "            'created': note['metadata'].get('created', ''),\n",
    "            'source': note['metadata'].get('source', '')\n",
    "        }\n",
    "        df_data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(df_data)\n",
    "    print(f\"üìä DataFrame created with {len(df)} notes\")\n",
    "    print(f\"üìã Columns: {list(df.columns)}\")\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(\"\\n=== Basic Statistics ===\")\n",
    "    print(df[['text_length', 'tag_count']].describe())\n",
    "else:\n",
    "    print(\"No data to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b6937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length distribution\n",
    "if 'df' in locals():\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(df['text_length'], bins=50, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Text Length (characters)')\n",
    "    plt.ylabel('Number of Notes')\n",
    "    plt.title('Distribution of Note Text Lengths')\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(df['tag_count'], bins=range(0, max(df['tag_count'])+2), alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Number of Tags')\n",
    "    plt.ylabel('Number of Notes')\n",
    "    plt.title('Distribution of Tag Counts')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"üìè Text length range: {df['text_length'].min()} - {df['text_length'].max()} characters\")\n",
    "    print(f\"üìè Median text length: {df['text_length'].median():.0f} characters\")\n",
    "    print(f\"üè∑Ô∏è  Tag count range: {df['tag_count'].min()} - {df['tag_count'].max()} tags\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89abe900",
   "metadata": {},
   "source": [
    "## Tag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605344d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze tag usage\n",
    "if 'df' in locals():\n",
    "    # Flatten all tags\n",
    "    all_tags = []\n",
    "    for tags in df['tags']:\n",
    "        all_tags.extend(tags)\n",
    "    \n",
    "    tag_counts = Counter(all_tags)\n",
    "    print(f\"üè∑Ô∏è  Total unique tags: {len(tag_counts)}\")\n",
    "    print(f\"üè∑Ô∏è  Total tag instances: {len(all_tags)}\")\n",
    "    \n",
    "    # Most common tags\n",
    "    print(\"\\n=== Top 20 Tags ===\")\n",
    "    for tag, count in tag_counts.most_common(20):\n",
    "        print(f\"{tag}: {count}\")\n",
    "    \n",
    "    # Notes without tags\n",
    "    untagged = df[df['tag_count'] == 0]\n",
    "    print(f\"\\nüìã Notes without tags: {len(untagged)} ({len(untagged)/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163e705",
   "metadata": {},
   "source": [
    "## Content Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de72722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample different types of notes\n",
    "if 'df' in locals():\n",
    "    print(\"=== Sample Notes by Length ===\")\n",
    "    \n",
    "    # Short note\n",
    "    short_notes = df[df['text_length'] < 100]\n",
    "    if not short_notes.empty:\n",
    "        short_sample = short_notes.iloc[0]\n",
    "        print(f\"\\nüìù SHORT NOTE (ID: {short_sample['id']})\")\n",
    "        print(f\"Title: {short_sample['title']}\")\n",
    "        print(f\"Tags: {short_sample['tags']}\")\n",
    "        print(f\"Text: {short_sample['text']}\")\n",
    "    \n",
    "    # Medium note\n",
    "    medium_notes = df[(df['text_length'] >= 500) & (df['text_length'] <= 1500)]\n",
    "    if not medium_notes.empty:\n",
    "        medium_sample = medium_notes.iloc[0]\n",
    "        print(f\"\\nüìÑ MEDIUM NOTE (ID: {medium_sample['id']})\")\n",
    "        print(f\"Title: {medium_sample['title']}\")\n",
    "        print(f\"Tags: {medium_sample['tags']}\")\n",
    "        print(f\"Text: {medium_sample['text'][:500]}...\")\n",
    "    \n",
    "    # Long note\n",
    "    long_notes = df[df['text_length'] > 2000]\n",
    "    if not long_notes.empty:\n",
    "        long_sample = long_notes.iloc[0]\n",
    "        print(f\"\\nüìö LONG NOTE (ID: {long_sample['id']})\")\n",
    "        print(f\"Title: {long_sample['title']}\")\n",
    "        print(f\"Tags: {long_sample['tags']}\")\n",
    "        print(f\"Text: {long_sample['text'][:500]}...\")\n",
    "        print(f\"(Full length: {long_sample['text_length']} characters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49050ee1",
   "metadata": {},
   "source": [
    "## Chunking Strategy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7162dc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze optimal chunking strategy\n",
    "if 'df' in locals():\n",
    "    print(\"=== Chunking Strategy Analysis ===\")\n",
    "    \n",
    "    # Typical embedding model context windows\n",
    "    embedding_limits = {\n",
    "        'text-embedding-3-small': 8191,  # tokens\n",
    "        'text-embedding-ada-002': 8191,\n",
    "    }\n",
    "    \n",
    "    # Rough estimation: 1 token ‚âà 4 characters for English text\n",
    "    chars_per_token = 4\n",
    "    \n",
    "    for model, token_limit in embedding_limits.items():\n",
    "        char_limit = token_limit * chars_per_token\n",
    "        \n",
    "        notes_over_limit = df[df['text_length'] > char_limit]\n",
    "        print(f\"\\n{model} (‚âà{char_limit:,} chars):\")\n",
    "        print(f\"  Notes over limit: {len(notes_over_limit)} ({len(notes_over_limit)/len(df)*100:.1f}%)\")\n",
    "        \n",
    "        if not notes_over_limit.empty:\n",
    "            print(f\"  Longest note: {notes_over_limit['text_length'].max():,} chars\")\n",
    "            print(f\"  Would need chunking: {notes_over_limit['text_length'].sum() / char_limit:.1f}x total chunks\")\n",
    "    \n",
    "    # Recommendation\n",
    "    print(\"\\n=== Chunking Recommendations ===\")\n",
    "    small_notes = len(df[df['text_length'] <= 1000])\n",
    "    medium_notes = len(df[(df['text_length'] > 1000) & (df['text_length'] <= 4000)])\n",
    "    large_notes = len(df[df['text_length'] > 4000])\n",
    "    \n",
    "    print(f\"Small notes (‚â§1000 chars): {small_notes} ({small_notes/len(df)*100:.1f}%)\")\n",
    "    print(f\"Medium notes (1000-4000 chars): {medium_notes} ({medium_notes/len(df)*100:.1f}%)\")\n",
    "    print(f\"Large notes (>4000 chars): {large_notes} ({large_notes/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nüí° Recommendation: Start with note-level chunking, split only notes >4000 chars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da670d3",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Based on this analysis, the next steps for BabyCoach development are:\n",
    "\n",
    "1. **Vector Store Setup**: Use ChromaDB for local development\n",
    "2. **Embedding Strategy**: Start with note-level embeddings using OpenAI `text-embedding-3-small`\n",
    "3. **Chunking**: Split only notes longer than 4000 characters\n",
    "4. **Metadata**: Leverage tags, titles, and dates for hybrid search\n",
    "5. **Testing**: Create queries that span different note types and topics\n",
    "\n",
    "The data looks well-structured and ready for RAG implementation!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
